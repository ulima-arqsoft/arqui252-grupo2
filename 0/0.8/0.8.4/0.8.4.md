> [0. Acerca del Grupo](../../0.md) ‚Ä∫ [0.8. Temas Individuales (Parte 2)](../0.8.md) ‚Ä∫ [0.8.4. Integrante 4](0.8.4.md)

# 0.8.4. Integrante 4

## Federated Learning: Entrenamiento Descentralizado y Privacidad de Datos

### ¬øQu√© es Federated Learning?
El Aprendizaje Federado (Federated Learning) es una t√©cnica de Machine Learning que permite entrenar un algoritmo a trav√©s de m√∫ltiples dispositivos descentralizados o servidores que contienen muestras de datos locales, sin intercambiarlos. Su objetivo es construir un modelo global robusto manteniendo la privacidad de los datos, ya que estos nunca salen del dispositivo del cliente; solo se comparten las actualizaciones de los par√°metros (pesos) del modelo.

### Funciones Principales
*   **Privacidad por Dise√±o:** Los datos sensibles permanecen en los nodos locales (clientes) y nunca se centralizan.
*   **Entrenamiento Descentralizado:** La computaci√≥n se distribuye entre los clientes, reduciendo la carga en el servidor central.
*   **Agregaci√≥n de Modelos:** Unificaci√≥n inteligente de los conocimientos adquiridos por cada cliente para mejorar el modelo global.
*   **Eficiencia de Ancho de Banda:** Solo se transmiten los pesos del modelo (kilobytes/megabytes) en lugar de terabytes de datos crudos.

### Componentes de la Arquitectura Federada

#### 1. Servidor Central (Aggregator)
Es el orquestador del proceso. No tiene acceso a los datos, solo gestiona el ciclo de vida del entrenamiento y mantiene el "Modelo Global".

*   **Funciones clave:**
    *   Selecci√≥n de clientes para cada ronda.
    *   Distribuci√≥n del modelo global actual.
    *   Recepci√≥n de actualizaciones (pesos) de los clientes.
    *   Agregaci√≥n de pesos (ej. algoritmo FedAvg).

#### 2. Clientes Federados (Edge Nodes)
Son los contenedores o dispositivos que poseen los datos y realizan el entrenamiento efectivo. En esta demo, simulan entidades aisladas con particiones de datos √∫nicas.

*   **Funciones clave:**
    *   Carga de dataset local (privado).
    *   Entrenamiento local (Local Epochs).
    *   Generaci√≥n de actualizaciones de pesos.
    *   Evaluaci√≥n del modelo global con datos locales.

#### 3. Protocolo de Comunicaci√≥n (Flower)
Framework que gestiona la mensajer√≠a segura entre cliente y servidor, generalmente sobre gRPC, permitiendo la sincronizaci√≥n de rondas y el transporte de tensores.

### Ciclo de Vida de una Ronda Federada
El servidor coordina el proceso invocando m√©todos espec√≠ficos en los clientes. Es obligatorio que cada cliente implemente la interfaz `NumPyClient` de Flower con los siguientes m√©todos, ya que el servidor los ejecutar√° autom√°ticamente en cada ronda:

1.  **`get_parameters()`**: El servidor solicita los pesos iniciales del modelo local para conocer su arquitectura y estado inicial.
2.  **`fit(parameters, config)`**: El servidor env√≠a los pesos del modelo global y solicita al cliente que inicie el entrenamiento local con sus datos privados. El cliente devuelve los pesos actualizados y el n√∫mero de muestras utilizadas.
3.  **`evaluate(parameters, config)`**: El servidor env√≠a el modelo global agregado y solicita al cliente que lo eval√∫e con su dataset de prueba local. El cliente devuelve m√©tricas de rendimiento (p√©rdida y exactitud).

Si estos m√©todos no est√°n definidos, el servidor no podr√° orquestar el entrenamiento y el proceso fallar√°.

### Importancia del Aprendizaje Federado
Esta arquitectura es fundamental para:

*   **Cumplimiento Normativo:** Adherencia estricta a GDPR, HIPAA y leyes de protecci√≥n de datos.
*   **Seguridad de Datos:** Minimiza la superficie de ataque al no tener una base de datos centralizada con toda la informaci√≥n.
*   **Latencia y Eficiencia:** Aprovecha el poder de c√≥mputo en el borde (Edge Computing).
*   **Colaboraci√≥n entre Entidades:** Permite que hospitales o bancos colaboren en un modelo com√∫n sin revelar informaci√≥n confidencial de sus pacientes o clientes.

### M√©tricas Clave en el Monitoreo
| M√©trica | Descripci√≥n | Uso |
| :--- | :--- | :--- |
| **Global Accuracy** | Precisi√≥n del modelo agregado evaluado en los clientes | Determinar la efectividad del aprendizaje conjunto |
| **Local Loss** | Error calculado durante el entrenamiento local | Evaluar qu√© tan bien se ajusta el modelo a los datos privados |
| **Round Duration** | Tiempo que toma completar una ronda de comunicaci√≥n | Identificar latencia en la red o cuellos de botella en clientes lentos |
| **Client Participation** | N√∫mero de clientes que completan exitosamente una ronda | Asegurar la representatividad del modelo global |

---

## Implementaci√≥n Tecnol√≥gica (DEMO)

### Framework: Flower (Flwr) sobre TensorFlow
Se utiliza **Flower**, un framework agn√≥stico y escalable para Federated Learning, junto con **TensorFlow** para la definici√≥n de la red neuronal (CNN).

*   **Estrategia:** `FedAvg` (Federated Averaging).
*   **Modelo:** Red Neuronal Convolucional (CNN) para clasificaci√≥n de im√°genes.
*   **Dataset:** MNIST particionado (Non-IID) para simular heterogeneidad de datos.

### Diagrama de Despliegue (Arquitectura de la Demo)

La aplicaci√≥n est√° compuesta por contenedores Docker orquestados que simulan una red real:

1.  **Server (Coordinador) - Puerto 8080**
    *   Ejecuta el servicio de Flower.
    *   Implementa la estrategia de agregaci√≥n y visualizaci√≥n de m√©tricas.
    *   Persiste resultados gr√°ficos en volumen compartido.

2.  **Clientes (Client 1, 2, 3)**
    *   Contenedores aislados con Python 3.10 y TensorFlow.
    *   **Client 1:** Posee √∫nicamente d√≠gitos 0-3.
    *   **Client 2:** Posee √∫nicamente d√≠gitos 4-6.
    *   **Client 3:** Posee √∫nicamente d√≠gitos 7-9.
    *   Cada uno entrena localmente y sube pesos al servidor.

---

## Construcci√≥n y Despliegue con Docker Compose

Esta secci√≥n detalla el proceso para preparar los datos, construir los contenedores y desplegar la federaci√≥n.

### Prerrequisitos
*   Docker Desktop instalado.
*   Python 3.x (para scripts de utilidad).

### Paso 1: Preparaci√≥n de Datos (Data Partitioning)
Antes de iniciar la federaci√≥n, se simula la separaci√≥n f√≠sica de los datos.

**Script:** `prepare_data.py`
Este script descarga MNIST y lo divide en carpetas estrictamente separadas:
*   `datasets/client1/`
*   `datasets/client2/`
*   `datasets/client3/`

**Ejecuci√≥n:**
```bash
docker compose run --rm setup
```

### Paso 2: Construcci√≥n de Im√°genes Docker
El proyecto utiliza un `Dockerfile` unificado para cliente y servidor para optimizar capas.

**Dockerfile (Resumen):**
```dockerfile
FROM python:3.10-slim
WORKDIR /app
RUN pip install tensorflow flwr numpy matplotlib
COPY . .
# El comando CMD se define en docker-compose seg√∫n el rol
```

### Paso 3: Orquestaci√≥n y Despliegue
El archivo `docker-compose.yml` define la topolog√≠a de la red federada.

**Comando de Despliegue:**
```bash
docker compose up --build
```

**Explicaci√≥n del flujo de despliegue:**
1.  Se levanta el servicio `server` en el puerto 8080.
2.  Se levantan los servicios `client1`, `client2` y `client3`.
3.  Los clientes montan sus vol√∫menes de datos respectivos (`./datasets/clientN`).
4.  Los clientes inician la conexi√≥n gRPC hacia `server:8080`.

---

## Configuraci√≥n de la Estrategia de Aprendizaje

La l√≥gica de federaci√≥n reside en `server.py`. Se ha implementado una estrategia personalizada para monitoreo en espa√±ol.

**Configuraci√≥n de FedAvg:**
*   **Min Fit Clients:** 3 (Requiere que los 3 clientes participen para entrenar).
*   **Rondas (Rounds):** 5 (Ciclos de entrenamiento-agregaci√≥n).
*   **Agregaci√≥n:** Promedio ponderado basado en el n√∫mero de muestras de cada cliente.

**Snippet de Configuraci√≥n:**
```python
strategy = SpanishPlottingStrategy(
    fraction_fit=1.0,
    min_fit_clients=3,
    evaluate_metrics_aggregation_fn=weighted_average,
)
```

---

## Monitoreo y Visualizaci√≥n de Resultados

El sistema incluye un m√≥dulo de observabilidad personalizado que genera reportes en tiempo real y gr√°ficos de evoluci√≥n.

### 1. Logs en Tiempo Real (Consola)
El servidor emite logs estructurados en espa√±ol indicando el progreso de cada ronda.

*   **Ejemplo de Log:**
    ```text
    üìä [Ronda 1] Resultados Globales:
       ‚úÖ Exactitud Promedio: 95.43%
       üìâ P√©rdida Promedio:   0.1429
    ```

### 2. Visualizaci√≥n Gr√°fica (Matplotlib)
Se ha implementado una clase `SpanishPlottingStrategy` que intercepta los resultados de cada ronda y genera un gr√°fico de l√≠nea.

*   **Ubicaci√≥n:** `results/evolucion_aprendizaje.png`
*   **Contenido:** Eje X (Rondas), Eje Y (Accuracy). Muestra c√≥mo el modelo global aprende a reconocer todos los d√≠gitos (0-9) aunque cada cliente solo haya visto una parte (ej. solo 0-3).

### 3. Verificaci√≥n de Logs Individuales
Para auditor√≠a, es posible inspeccionar el comportamiento de un nodo espec√≠fico:

```bash
# Ver logs del servidor
docker compose logs -f server

# Ver logs de un cliente espec√≠fico
docker compose logs -f client1
```


[‚¨ÖÔ∏è Anterior](../0.8.3/0.8.3.md) | [üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../0.8.5/0.8.5.md)