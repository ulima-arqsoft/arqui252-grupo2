> [0. Acerca del Grupo](../../0.md) ‚Ä∫ [0.7. Trabajo Individual (Patrones Cloud)](../0.7.md) ‚Ä∫ [0.7.4. Integrante 4](0.7.4.md)

# 0.7.4. Integrante 4



## PATR√ìN COMPETING CONSUMERS (CONSUMIDORES COMPETIDORES)

### PROBLEMA
El patr√≥n Competing Consumers resuelve el cuello de botella que se genera cuando un √∫nico consumidor debe procesar m√∫ltiples mensajes o tareas de forma secuencial. Los principales problemas que aborda son:

- **Acumulaci√≥n de mensajes**: la cola crece m√°s r√°pido de lo que puede procesarse.
- **Latencia elevada**: tiempos de espera prolongados antes del procesamiento.
- **Subutilizaci√≥n de recursos**: un solo consumidor no aprovecha la capacidad disponible.
- **Falta de escalabilidad**: imposibilidad de ajustar la capacidad seg√∫n la demanda.
- **Punto √∫nico de fallo**: si el consumidor falla, todo el procesamiento se detiene.

Adicionalmente, cuando algunos mensajes requieren m√°s tiempo que otros, se bloquea el procesamiento de tareas m√°s simples. Tambi√©n existe riesgo de p√©rdida de mensajes ante fallos y dificultad para responder a picos repentinos de carga.

### SOLUCI√ìN
El patr√≥n propone m√∫ltiples consumidores concurrentes que compiten por procesar mensajes de la misma cola, distribuyendo autom√°ticamente la carga de trabajo entre todos los disponibles.

Los componentes clave son:

- **Cola de mensajes**: act√∫a como buffer y garantiza que cada mensaje sea procesado por un solo consumidor mediante mecanismos de bloqueo.
- **Grupo de consumidores**: instancias id√©nticas operando independientemente solicitando mensajes, proces√°ndolos y confirmando su ejecuci√≥n.
- **Mecanismo de distribuci√≥n**: puede ser rotativo, basado en carga actual, por prioridad o aleatorio.

Tecnolog√≠as comunes incluyen Azure Service Bus, Amazon SQS, RabbitMQ, Apache Kafka y Google Cloud Pub/Sub.

A diferencia de otros patrones, Competing Consumers garantiza que cada mensaje sea procesado exactamente por un consumidor, mientras que en Publicaci√≥n-Suscripci√≥n un mensaje llega a m√∫ltiples suscriptores. Su objetivo principal es distribuir eficientemente la carga de trabajo mediante escalabilidad horizontal.

### CASOS DE APLICACI√ìN

#### Caso 1: Procesamiento de Pedidos en E-commerce
Plataformas como Amazon o MercadoLibre reciben miles de pedidos por minuto durante eventos especiales. Cuando un usuario completa una compra, m√∫ltiples consumidores compiten por validar inventario, procesar pagos, generar facturas, notificar a log√≠stica y enviar confirmaciones. Durante Black Friday, el sistema escala autom√°ticamente de cincuenta a quinientos consumidores. Si algunos fallan, los dem√°s contin√∫an operando. El rendimiento aumenta de doscientos a m√°s de diez mil pedidos por minuto, con confirmaciones en segundos en lugar de minutos.

#### Caso 2: Procesamiento de Im√°genes en Redes Sociales
Instagram y TikTok procesan millones de fotos y videos diariamente que requieren generar miniaturas, detectar contenido inapropiado, extraer metadatos y optimizar para diferentes dispositivos. Consumidores especializados con GPU ejecutan modelos de inteligencia artificial, mientras otros optimizados para CPU generan miniaturas. El procesamiento paralelo reduce el tiempo de treinta segundos a tres segundos. Instagram procesa aproximadamente noventa y cinco millones de fotos diarias.

#### Caso 3: Sistema de Notificaciones Multicanal
Una startup SaaS env√≠a notificaciones por correo electr√≥nico, SMS, push, webhooks y dentro de la aplicaci√≥n. Grupos especializados de consumidores manejan cada canal: veinte para email usando SendGrid, quince para SMS con Twilio, diez para notificaciones push mediante Firebase. Cada grupo respeta las limitaciones de velocidad de las APIs externas e implementa reintentos inteligentes. Un caso real mostr√≥ crecimiento de mil a quinientas mil notificaciones diarias con sesenta por ciento de reducci√≥n en costos versus servicios completamente administrados.

#### Caso 4: An√°lisis de Registros y Monitoreo
Empresas corporativas generan terabytes de registros diarios de servidores, microservicios, bases de datos e infraestructura de red. Los registros fluyen a Kafka donde consumidores compiten para analizar, normalizar, enriquecer con informaci√≥n adicional, agregar m√©tricas, indexar en Elasticsearch y evaluar reglas de alertas. El procesamiento distribuido garantiza que los registros est√©n disponibles en menos de cinco segundos. Diferentes grupos de consumidores manejan pol√≠ticas de retenci√≥n escribiendo a almacenamiento caliente, tibio o fr√≠o seg√∫n la antig√ºedad.

#### Caso 5: Procesamiento de Transacciones Bancarias
Bancos digitales procesan transferencias, pagos de servicios, dep√≥sitos y validaci√≥n de fraude en tiempo real. La arquitectura usa colas con sesiones para garantizar orden por usuario, cien instancias de consumidores con sesiones persistentes, y monitoreo estricto. Los requisitos incluyen disponibilidad del noventa y nueve punto noventa y nueve por ciento, latencia menor a tres segundos en el percentil noventa y nueve, capacidad de cincuenta mil transacciones por minuto, y cumplimiento de est√°ndares regulatorios como SOC 2 y PCI-DSS.

### Aplicaci√≥n en su Proyecto Grupal

En nuestro proyecto, espec√≠ficamente en el m√≥dulo de Rese√±as y Calificaciones, integramos el patr√≥n Competing Consumers para desacoplar y paralelizar el procesamiento de reportes de rese√±as (Report Processor).

Objetivo pr√°ctico: evitar que la API que recibe reportes se convierta en un cuello de botella y permitir escalado horizontal de los workers que realizan validaciones asincr√≥nicas sobre las rese√±as reportadas.

C√≥mo aporta valor al sistema:

- Reduce la latencia percibida por el usuario (la API responde r√°pido tras encolar la tarea de procesamiento del reporte). 
- Permite escalar workers de forma independiente seg√∫n la carga de reportes recibidos.
- Elimina el punto √∫nico de fallo: si un worker cae, otros contin√∫an procesando la cola de reportes.
- Facilita el manejo de picos de reportes (colas act√∫an como buffer) y la observabilidad (m√©tricas en RabbitMQ / logs de workers).

Mapeo concreto con la infraestructura de pruebas:

- Cola: `review-reports-queue` en RabbitMQ (workers broker).
- Workers: 2 instancias de `report-worker` compitiendo por mensajes.
- Cache: Redis para invalidar datos derivados cuando una rese√±a acumula suficientes reportes.
- Persistencia: PostgreSQL (Neon) para almacenar rese√±as, calificaciones detalladas y reportes.

Validaci√≥n y criterios de √©xito en el proyecto:

- Latencia API: la API debe devolver respuesta inicial (aceptaci√≥n del reporte) en < 200ms en condiciones normales.
- Throughput: los workers deben procesar 30 mensajes de report en los tests de integraci√≥n.
- Distribuci√≥n: los mensajes deben distribuirse entre los workers de forma balanceada (aproximadamente 15 por worker).
- Consistencia: las tablas en PostgreSQL deben persistir los reportes creados por los tests y el cache de Redis debe invalidarse cuando una rese√±a acumula ‚â•3 reportes.

Se validar√° con los scripts de prueba provistos en `tests/` y con las herramientas de observaci√≥n: RabbitMQ Management UI, logs Docker y consultas SQL a PostgreSQL.

### Desarrollo de C√≥digo y Demo

Descripci√≥n del caso demo implementado en el repositorio de pruebas:

- Escenario: 50 rese√±as creadas v√≠a API (para poblar la BD), seguidas de 30 reportes que publican mensajes a `review-reports-queue` para ser procesados por m√∫ltiples workers compitiendo.
- Infraestructura m√≠nima usada en la demo: RabbitMQ (workers broker), Redis, API principal y 2 instancias de report-worker (docker-compose los crea y levanta).

Archivos y artefactos relevantes:

- `docker-compose.yml` (levanta RabbitMQ, Redis, API y workers de prueba)
- `tests/01-seed-data.sql` ‚Äì script SQL para poblar datos necesarios (usuarios, profesor, caches).
- `tests/02-create-reviews.js` ‚Äì script que crea 50 rese√±as mediante llamadas a la API (√∫til para poblar la BD para pruebas de reportes; no publica a colas).
- `tests/03-test-reports-competing.js` ‚Äì script que crea 30 reportes y publica mensajes a `review-reports-queue`.


Pasos ejecutados para implementar la demo (paso a paso):

1. Preparar datos de prueba

	- Conectar a la base de datos PostgreSQL o adaptar a la base de datos correspondiente y ejecutar `tests/01-seed-data.sql` para crear usuarios, profesor y caches.

	Estas tablas reflejan la estructura m√≠nima necesaria para que los scripts de prueba funcionen correctamente.

```sql
-- Usuarios en cache (seg√∫n el script proporcionado)
CREATE TABLE IF NOT EXISTS usuarios_cache (
	id INTEGER PRIMARY KEY,
	nombre TEXT NOT NULL,
	fecha_sincronizacion TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Profesores en cache (columnas: id, nombre, apellido, email, fecha_sincronizacion)
CREATE TABLE IF NOT EXISTS profesores_cache (
	id INTEGER PRIMARY KEY,
	nombre TEXT NOT NULL,
	apellido TEXT,
	email TEXT,
	fecha_sincronizacion TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Cursos en cache (id, codigo, nombre, fecha_sincronizacion)
CREATE TABLE IF NOT EXISTS cursos_cache (
	id INTEGER PRIMARY KEY,
	codigo TEXT,
	nombre TEXT,
	fecha_sincronizacion TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Categor√≠as de calificaci√≥n (nombres y flag activo)
CREATE TABLE IF NOT EXISTS categorias_calificacion_cache (
	id INTEGER PRIMARY KEY,
	nombre TEXT NOT NULL,
	activo BOOLEAN DEFAULT true,
	fecha_sincronizacion TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Tipos de reporte
CREATE TABLE IF NOT EXISTS tipos_reporte_cache (
	id INTEGER PRIMARY KEY,
	nombre TEXT NOT NULL,
	fecha_sincronizacion TIMESTAMP WITH TIME ZONE DEFAULT now()
);


-- Tabla principal de rese√±as
CREATE TABLE IF NOT EXISTS resenas (
	id SERIAL PRIMARY KEY,
	id_usuario INTEGER NOT NULL REFERENCES usuarios_cache(id),
	id_profesor INTEGER NOT NULL REFERENCES profesores_cache(id),
	id_curso INTEGER REFERENCES cursos_cache(id),
	texto TEXT,
	id_estado INTEGER REFERENCES estados_resena_cache(id),
	creado_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Calificaciones detalladas por rese√±a (usar categorias_calificacion_cache)
CREATE TABLE IF NOT EXISTS calificaciones_detalladas (
	id SERIAL PRIMARY KEY,
	id_resena INTEGER NOT NULL REFERENCES resenas(id) ON DELETE CASCADE,
	id_categoria INTEGER NOT NULL REFERENCES categorias_calificacion_cache(id),
	puntaje NUMERIC(5,2) NOT NULL,
	creado_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Reportes hechos por usuarios sobre rese√±as
CREATE TABLE IF NOT EXISTS reportes (
	id SERIAL PRIMARY KEY,
	id_resena INTEGER NOT NULL REFERENCES resenas(id) ON DELETE CASCADE,
	id_usuario INTEGER NOT NULL REFERENCES usuarios_cache(id),
	id_tipo_reporte INTEGER NOT NULL REFERENCES tipos_reporte_cache(id),
	comentario TEXT,
	creado_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);


```

Notas importantes:

- El script de pruebas asume que existen las tablas con los nombres exactos mostrados arriba (`categorias_calificacion_cache`, `tipos_reporte_cache`, etc.). Si su base de datos usa nombres diferentes, adapte el script o cree vistas/aliases.
- Aseg√∫rese de que el profesor de prueba tenga `id = 1`, el curso `id = 1` y usuarios con ids en el rango 1..200 para mantener compatibilidad con los tests.



2. Levantar la infraestructura (desde la ra√≠z del proyecto)

```cmd
docker-compose up -d
```

	- Esto inicia RabbitMQ (workers broker), Redis, la API y los workers de prueba (report-worker-1..2).

3. Verificar contenedores

```cmd
docker-compose ps
```

4. Instalar dependencias para los scripts de prueba (carpeta `tests`)

```cmd
cd tests
npm install
```

5. Ejecutar script de creaci√≥n de rese√±as (poblar BD)

```cmd
node tests/02-create-reviews.js
```

	- Nota: este script crea rese√±as directamente v√≠a la API para permitir probar el procesamiento de reportes posteriormente.

6. Ejecutar test de Report Processor (Competing Consumers)

```cmd
node tests/03-test-reports-competing.js
```

	- Monitorea procesamiento en:

```cmd
docker-compose logs -f report-worker-1 report-worker-2
```




Validaci√≥n y m√©tricas esperadas (resumen):

- Creaci√≥n de rese√±as: 50 rese√±as creadas en la base de datos por `tests/02-create-reviews.js`.
- Report Processor (Competing Consumers): 30 mensajes publicados a `review-reports-queue`; distribuci√≥n aproximada 15 por worker.


### Repositorio de C√≥digo Demo

Para copiar y ejecutar la implementaci√≥n completa del patr√≥n Competing Consumers en el procesamiento de reportes, accede al siguiente repositorio (excluyendo la configuraci√≥n de base de datos, que debe adaptarse localmente):

[Repositorio Demo: Calificaciones y Reportes](https://github.com/ulima-arqsoft/arqui252-cabezas-diaz/tree/main/TrabajoIndividualDemoParte2/CalificacionesReportes)

---

### Verificaci√≥n: captura de logs de workers

La siguiente imagen muestra una captura de los logs de los workers durante la ejecuci√≥n de las pruebas (verifica que los `report-worker` procesan mensajes):

![Workers logs ‚Äî verificaci√≥n](WorkersLogs.png)

[‚¨ÖÔ∏è Anterior](../0.7.3/0.7.3.md) | [üè† Home](../../../README.md) | [Siguiente ‚û°Ô∏è](../0.7.5/0.7.5.md)